from benchmark.runner import run_full_benchmark, run_quick_benchmark
import json
import os
import matplotlib.pyplot as plt
from benchmark.graphs import generate_complete_graphs  # fun√ß√£o que gera todos os gr√°ficos

ALL_RESULTS_FILE = "benchmark/results/all_results.json"   # benchmark completo
QUICK_RESULTS_FILE = "benchmark/results/quick_results.json"  # teste r√°pido


# -------------------------
#  FORMATA√á√ÉO EM TABELA
# -------------------------
def format_table(result_dict):
    output = ""

    for method, patterns in result_dict.items():
        output += f"\n‚ñ∂ {method}\n"

        for pattern_name in ["random", "sorted", "reversed"]:
            line = f"{pattern_name.capitalize()} -> "
            p = patterns.get(pattern_name)

            if p and p.get("time_ms") is not None:
                # fallback seguro caso m√©tricas n√£o existam
                time_ms = p.get("time_ms")
                mem = p.get("memory_kb", 0.0)
                comp = p.get("comparisons", 0)
                swaps = p.get("swaps", 0)

                line += (
                    f"tempo: {time_ms:.2f}ms | "
                    f"mem√≥ria: {mem:.2f}KB | "
                    f"comparisons: {comp} | swaps: {swaps}"
                )
            else:
                line += "‚ùå n√£o executado"

            output += line + "\n"

    return output


# -------------------------
#  EXIBIR RESULTADOS SALVOS
# -------------------------
def show_saved_results(filename, title):
    if not os.path.exists(filename):
        print(f"\n‚ùå Nenhum {title} salvo ainda!")
        return

    print(f"\n=== {title.upper()} ===\n")

    with open(filename, "r") as f:
        all_results = json.load(f)

    for size, algos in all_results.items():
        print(f"\nüìå {size} m√∫sicas:")
        print(format_table(algos))


# -------------------------
#  NOVA FUN√á√ÉO: TABELAS DETALHADAS
# -------------------------
def show_detailed_tables(filename):
    if not os.path.exists(filename):
        print(f"\n‚ùå Nenhum resultado salvo em {filename}")
        return

    with open(filename, "r") as f:
        results = json.load(f)

    for algo in next(iter(results.values())).keys():  # pega todos os algoritmos
        print(f"\n================ {algo} =================\n")
        for pattern in ["random", "sorted", "reversed"]:
            print(f"--- Padr√£o: {pattern.capitalize()} ---")
            print(f"{'Tamanho':>12} | {'Tempo(ms)':>15} | {'Mem√≥ria(KB)':>15} | {'Comparisons':>15} | {'Swaps':>10}")
            print("-" * 75)
            for size in sorted([int(s) for s in results.keys()]):
                metrics = results[str(size)][algo].get(pattern, {})
                if metrics.get("time_ms") is None:
                    print(f"{size:>12} | {'-':>15} | {'-':>15} | {'-':>15} | {'-':>10}")
                else:
                    # Formata√ß√£o com v√≠rgula decimal e ponto de milhar
                    time_fmt = f"{metrics.get('time_ms',0):,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
                    mem_fmt = f"{metrics.get('memory_kb',0):,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
                    comp_fmt = f"{metrics.get('comparisons',0):,}".replace(",", ".")
                    swaps_fmt = f"{metrics.get('swaps',0):,}".replace(",", ".")
                    print(f"{size:>12} | {time_fmt:>15} | {mem_fmt:>15} | {comp_fmt:>15} | {swaps_fmt:>10}")
            print("\n")



# -------------------------
#  MENU PRINCIPAL
# -------------------------
def main():
    while True:
        print("\n=== MENU ===")
        print("1 - Executar benchmark COMPLETO (demorado)")
        print("2 - Executar benchmark R√ÅPIDO")
        print("3 - Mostrar resultados COMPLETOS salvos")
        print("4 - Mostrar resultados R√ÅPIDOS salvos")
        print("5 - Gerar gr√°ficos a partir do benchmark completo")
        print("6 - Sair")
        print("7 - Mostrar tabelas detalhadas do benchmark completo")

        opt = input("\nEscolha uma op√ß√£o: ")

        if opt == "1":
            print("\n‚è≥ Rodando benchmark COMPLETO...")
            run_full_benchmark()
            print(f"\n‚úÖ Benchmark completo salvo em {ALL_RESULTS_FILE}")

        elif opt == "2":
            print("\n‚ö° Rodando benchmark R√ÅPIDO...")
            run_quick_benchmark()
            print(f"\n‚úÖ Benchmark r√°pido salvo em {QUICK_RESULTS_FILE}")

        elif opt == "3":
            show_saved_results(ALL_RESULTS_FILE, "resultado do benchmark completo")

        elif opt == "4":
            show_saved_results(QUICK_RESULTS_FILE, "resultado do benchmark r√°pido")

        elif opt == "5":
            print("\nüìä Gerando gr√°ficos a partir do benchmark completo...")
            generate_complete_graphs()  # chama fun√ß√£o para gerar gr√°ficos

        elif opt == "6":
            print("Saindo...")
            break

        elif opt == "7":
            print("\nüìã Mostrando tabelas detalhadas do benchmark completo...")
            show_detailed_tables(ALL_RESULTS_FILE)

        else:
            print("Op√ß√£o inv√°lida.")


if __name__ == "__main__":
    main()
